summarise(RankTotal = sum(Rank_del_Pais, na.rm = TRUE)) %>%
arrange(RankTotal)
# 4. Resultado
print(ranking_final)
# ============================
# Modelo Macro con efectos fijos
# ============================
#Ya tenemos cargada la base de macros, y transformada en P0.
# Estimamos con efectos fijos
modelo_macro_fe <- feols(
Precio_Unitario_Promedio ~ GDPpc_miles + Arancel + UrbGrow +
LPI + Inflacion + Import_PIB + FoodImp | Sub_categoria + Ano,
data = data_macro
)
summary(modelo_macro_fe)
# ============================
# Modelo Micro con efectos fijos
# ============================
#Datos cargados micro en P0.
modelo_micro_fe <- feols(
PrecioU_oferta_usd ~ MarcaPropia + Promocion + Cadena |
Categoria + Pais + Ano,
data = data_micro
)
summary(modelo_micro_fe)
#automatic variable selection
#1. Construcción de la base filtrando NA
data_macro_lasso <- data_macro %>%
dplyr::select(Precio_Unitario_Promedio, GDPpc_miles, Arancel, UrbGrow, LPI, Inflacion, Import_PIB, FoodImp) %>%
na.omit()
# 2. Variable dependiente
y_macro <- as.matrix(data_macro_lasso$Precio_Unitario_Promedio)
# 3. Matriz de regresores (incluye efectos fijos como dummies)
X_macro <- model.matrix( Precio_Unitario_Promedio ~ GDPpc_miles + Arancel + UrbGrow + LPI + Inflacion + Import_PIB + FoodImp , data = data_macro_lasso )[, -1] # quitamos el intercepto
# 4. Estimación con LASSO y validación cruzada
set.seed(123) # para replicabilidad
cv_macro_lasso <- cv.glmnet(X_macro, y_macro, alpha = 1, standardize = TRUE)
# 5. Lambda óptimo elegido por CV
cat("Lambda óptimo:", cv_macro_lasso$lambda.min, "\n")
# 6. Coeficientes del modelo
coef_macro <- coef(cv_macro_lasso, s = "lambda.min")
# 7. Variables seleccionadas(coef distinto de 0)
selected_vars <- rownames(coef_macro)[which(coef_macro != 0)]
cat("Variables seleccionadas por LASSO:\n")
print(selected_vars)
# 1. Construcción de la base filtrando NA
data_micro_lasso <- data_micro %>%
dplyr::select(PrecioU_oferta_usd, MarcaPropia, Promocion, Cadena, Categoria, Pais, Ano) %>%
na.omit()
# 2. Variable dependiente
y_micro <- as.matrix(data_micro_lasso$PrecioU_oferta_usd)
# 3. Matriz de regresores (incluye efectos fijos como dummies)
X_micro <- model.matrix(
PrecioU_oferta_usd ~ MarcaPropia + Promocion + Cadena +
factor(Categoria) + factor(Pais) + factor(Ano),
data = data_micro_lasso
)[, -1]   # quitamos el intercepto
# 4. Estimación con LASSO y validación cruzada
set.seed(123)  # para replicabilidad
cv_micro_lasso <- cv.glmnet(X_micro, y_micro, alpha = 1, standardize = TRUE)
# 5. Lambda óptimo elegido por CV
cat("Lambda óptimo:", cv_micro_lasso$lambda.min, "\n")
# 6. Coeficientes del modelo
coef_micro <- coef(cv_micro_lasso, s = "lambda.min")
# 7. Variables seleccionadas (coef distinto de 0)
selected_vars_micro <- rownames(coef_micro)[which(coef_micro != 0)]
# Filtrar: eliminar intercepto, dummies de Categoria, Pais y Ano
selected_vars_micro_clean <- selected_vars_micro[!grepl("Intercept|Categoria|Pais|Ano", selected_vars_micro)]
cat("Variables seleccionadas por LASSO (solo micro, sin FE):\n")
print(selected_vars_micro_clean)
# Asumimos que tu dataframe original se llama 'data_micro'
# --- PASO CLAVE: LIMPIEZA DE DATOS ---
# Eliminamos las filas donde el precio sea NA antes de hacer cualquier otra cosa
data_limpia <- data_micro %>%
filter(!is.na(PrecioU_oferta_usd))
# --- Ahora sí, dividimos el dataframe LIMPIO ---
set.seed(123) # Para que la división de datos sea reproducible
# Dividir los datos en entrenamiento (80%) y prueba (20%)
indices_entrenamiento <- createDataPartition(data_limpia$PrecioU_oferta_usd, p = 0.8, list = FALSE)
datos_entrenamiento <- data_limpia[indices_entrenamiento, ]
datos_prueba <- data_limpia[-indices_entrenamiento, ]
# --- ENTRENAMIENTO DE MODELOS ---
# 1. Modelo de Regresión Lineal (como base de comparación)
modelo_lm <- lm(PrecioU_oferta_usd ~ Promocion + Marca_propia + Cadena, data = datos_entrenamiento)
# 2. Modelo k-Nearest Neighbors (kNN)
control_entrenamiento <- trainControl(method = "cv", number = 10)
modelo_knn <- train(PrecioU_oferta_usd ~ Promocion + Marca_propia + Cadena,
data = datos_entrenamiento,
method = "knn",
trControl = control_entrenamiento,
preProcess = c("center", "scale"),
tuneGrid = expand.grid(k = c(3, 5, 7, 9)))
# Asumimos que tu dataframe original se llama 'data_micro'
# --- PASO CLAVE: LIMPIEZA DE DATOS ---
# Eliminamos las filas donde el precio sea NA antes de hacer cualquier otra cosa
# --- Ahora sí, dividimos el dataframe LIMPIO ---
set.seed(123) # Para que la división de datos sea reproducible
# Dividir los datos en entrenamiento (80%) y prueba (20%)
indices_entrenamiento <- createDataPartition(data_micro$PrecioU_oferta_usd, p = 0.8, list = FALSE)
# --- P3 con gráficos estilo Sesión 04 (base: precio_por_pais) ---
set.seed(5162)
# 0) Verificar columnas
req <- c("Ano","Mes","Pais","Sub_categoria","Precio_Unitario_Promedio")
stopifnot(all(req %in% names(precio_por_pais)))
View(precio_por_subcategoria)
# --- P3 con gráficos estilo Sesión 04 (base: precio_por_pais) ---
set.seed(5162)
# 0) Verificar columnas
req <- c("Ano","Mes","Pais","Sub_categoria","Precio_Unitario_Promedio")
stopifnot(all(req %in% names(precio_por_subcategoria)))
# 1) Dataset y factores
data_ag <- precio_por_subcategoria %>%
dplyr::select(all_of(req)) %>%
dplyr::mutate(
Pais          = as.factor(Pais),
Sub_categoria = as.factor(Sub_categoria),
Ano           = as.integer(Ano),
Mes           = as.integer(Mes)
) %>%
dplyr::filter(is.finite(Precio_Unitario_Promedio))
# (Opcional) colapsar subcategorías muy raras
min_count <- 5
tab_sc <- table(data_ag$Sub_categoria)
rare_sc <- names(tab_sc)[tab_sc < min_count]
if (length(rare_sc) > 0) {
data_ag$Sub_categoria <- forcats::fct_other(
data_ag$Sub_categoria,
keep = setdiff(levels(data_ag$Sub_categoria), rare_sc),
other_level = "Otros"
)
}
# 2) Split 80/20 estratificado por Sub_categoria
set.seed(5162)
idx <- caret::createDataPartition(data_ag$Sub_categoria, p = 0.8, list = FALSE)
train_df <- data_ag[idx, ]
test_df  <- data_ag[-idx, ]
# 3) Fórmula (solo variables de la tabla agregada)
fml <- Precio_Unitario_Promedio ~ Pais + Sub_categoria + Ano + Mes
# 4) Limpieza robusta
train_df <- train_df %>% dplyr::filter(!is.na(Precio_Unitario_Promedio))
mf_train <- model.frame(fml, data = train_df, na.action = na.pass)
stopifnot(nrow(mf_train) == nrow(train_df))
ok_train <- stats::complete.cases(mf_train)
train_clean <- train_df[ok_train, , drop = FALSE]
# 5) Control CV (10 folds)
ctrl <- caret::trainControl(method = "cv", number = 10)
# 6.1 LM (con resumen tipo modelsummary)
train.lm <- lm(fml, data = train_clean)
modelsummary(train.lm,
fmt = 3,
estimate = "{estimate}{stars}({std.error})",
statistic = NULL,
gof_map = c("nobs","adj.r.squared","rmse"))
# 6.2 MARS con gráfico de tuning (ggplot(train.mars))
set.seed(5162)
train.mars <- caret::train(
fml, data = train_clean, method = "earth",
trControl = ctrl,
preProcess = c("center","scale"),
tuneGrid = expand.grid(degree = c(1,2), nprune = 5:12)
)
# Gráfico estilo Sesión 04
print(ggplot(train.mars))
# 6.3 Random Forest con gráfico de tuning (ggplot(train.rf))
p <- length(all.vars(update(fml, . ~ . - Precio_Unitario_Promedio)))
mtry_heur <- max(1, floor(sqrt(p)))
grid_rf <- expand.grid(mtry = unique(pmax(1, c(mtry_heur-1, mtry_heur, mtry_heur+1))))
set.seed(5162)
train.rf <- caret::train(
fml, data = train_clean, method = "rf",
trControl = ctrl,
preProcess = c("center","scale"),
tuneGrid = grid_rf,
ntree = 300,
importance = TRUE
)
# Gráfico estilo Sesión 04
print(ggplot(train.rf))
# 7) Evaluación en test
test_eval_mf <- model.frame(fml, data = test_df, na.action = na.pass)
ok_test <- stats::complete.cases(test_eval_mf)
test_clean <- test_df[ok_test, , drop = FALSE]
test_clean <- test_clean %>% dplyr::filter(!is.na(Precio_Unitario_Promedio))
pred.lm   <- predict(train.lm,   newdata = test_clean)
pred.mars <- predict(train.mars, newdata = test_clean)
pred.rf   <- predict(train.rf,   newdata = test_clean)
err.lm   <- test_clean$Precio_Unitario_Promedio - pred.lm
err.mars <- test_clean$Precio_Unitario_Promedio - pred.mars
err.rf   <- test_clean$Precio_Unitario_Promedio - pred.rf
rmse <- function(e) sqrt(mean(e^2, na.rm = TRUE))
mae  <- function(e) mean(abs(e), na.rm = TRUE)
mse  <- function(e) mean(e^2, na.rm = TRUE)
metrics <- data.frame(
Modelo = c("LM","MARS","RandomForest"),
RMSE   = c(rmse(err.lm), rmse(err.mars), rmse(err.rf)),
MAE    = c(mae (err.lm), mae (err.mars), mae (err.rf)),
MSE    = c(mse (err.lm), mse (err.mars), mse (err.rf))
)
print(metrics)
# 8) Boxplots de errores (como en el archivo del profe)
error.test <- data.frame(
lm   = err.lm,
mars = err.mars,
rf   = err.rf
)
par(mfrow = c(1,2))
boxplot(error.test); title(main="ML models", sub="Forecasting Errors")
boxplot(abs(error.test)); title(main="ML models", sub="Forecasting Absolute Errors")
par(mfrow = c(1,1))
# newdata alineado con niveles de entrenamiento
new_caso <- data.frame(
Pais = factor("Chile", levels = levels(train_clean$Pais)),
Sub_categoria = factor("Aceite", levels = levels(train_clean$Sub_categoria)),
Ano  = 2022L,
Mes  = 2L
)
pred_puntual <- data.frame(
Modelo = c("LM","MARS","RandomForest"),
Prediccion = c(
predict(fit_lm,   newdata = new_caso),
predict(fit_mars, newdata = new_caso),
predict(fit_rf,   newdata = new_caso)
)
)
# newdata alineado con niveles de entrenamiento
new_caso <- data.frame(
Pais = factor("Chile", levels = levels(train_clean$Pais)),
Sub_categoria = factor("Aceite", levels = levels(train_clean$Sub_categoria)),
Ano  = 2022L,
Mes  = 2L
)
pred_puntual <- data.frame(
Modelo = c("LM","MARS","RandomForest"),
Prediccion = c(
predict(train.lm,   newdata = new_caso),
predict(train.mars, newdata = new_caso),
predict(train.rf,   newdata = new_caso)
)
)
# Observado desde la base agregada
obs <- data_ag %>%
dplyr::filter(Ano==2022, Mes==2, Pais=="Chile", Sub_categoria=="Aceite") %>%
dplyr::slice(1) %>%
dplyr::pull(Precio_Unitario_Promedio)
pred_puntual$Observado <- obs
print(pred_puntual)
library(caret)
# # --- Carga de librerías ---
library(caret); library(dplyr); library(randomForest); library(earth)
# --- 1. Preparación de datos (más compacto) ---
set.seed(5162)
data_clean <- precio_por_subcategoria %>%
select(Ano, Mes, Pais, Sub_categoria, Precio_Unitario_Promedio) %>%
mutate(across(c(Pais, Sub_categoria), as.factor)) %>%
filter(is.finite(Precio_Unitario_Promedio))
# --- 2. División de datos ---
idx <- createDataPartition(data_clean$Sub_categoria, p = 0.8, list = FALSE)
train_df <- data_clean[idx, ]
test_df  <- data_clean[-idx, ]
fml <- Precio_Unitario_Promedio ~ . # Usar todas las demás variables como predictores
# --- 3. Entrenamiento de modelos ---
ctrl <- trainControl(method = "cv", number = 10, savePredictions = "final")
# Entrenamos los 3 modelos
modelo_lm   <- train(fml, data = train_df, method = "lm", trControl = ctrl)
modelo_mars <- train(fml, data = train_df, method = "earth", trControl = ctrl, tuneGrid = expand.grid(degree=1, nprune=5:12))
modelo_rf   <- train(fml, data = train_df, method = "rf", trControl = ctrl, tuneGrid = expand.grid(mtry = 2:4), ntree = 100)
# --- 4. Comparación directa de modelos ---
# caret tiene una función específica para comparar modelos entrenados
model_list <- list(LM = modelo_lm, MARS = modelo_mars, RF = modelo_rf)
results <- resamples(model_list)
# Imprimir resumen de métricas y gráfico de cajas
summary(results)
bwplot(results, metric = "RMSE")
# --- 5. Predicción puntual (más directo) ---
new_caso <- data.frame(
Pais = factor("Chile", levels = levels(train_df$Pais)),
Sub_categoria = factor("Aceite", levels = levels(train_df$Sub_categoria)),
Ano  = 2022,
Mes  = 2
)
cat("\nPredicciones para el caso puntual:\n")
sapply(model_list, function(modelo) predict(modelo, newdata = new_caso))
# newdata alineado con niveles de entrenamiento
new_caso <- data.frame(
Pais = factor("Chile", levels = levels(train_clean$Pais)),
Sub_categoria = factor("Aceite", levels = levels(train_clean$Sub_categoria)),
Ano  = 2022L,
Mes  = 2L
)
pred_puntual <- data.frame(
Modelo = c("LM","MARS","RandomForest"),
Prediccion = c(
predict(train.lm,   newdata = new_caso),
predict(train.mars, newdata = new_caso),
predict(train.rf,   newdata = new_caso)
)
)
# Observado desde la base agregada
obs <- data_ag %>%
dplyr::filter(Ano==2022, Mes==2, Pais=="Chile", Sub_categoria=="Aceite") %>%
dplyr::slice(1) %>%
dplyr::pull(Precio_Unitario_Promedio)
pred_puntual$Observado <- obs
print(pred_puntual)
set.seed(5162)
train.rf <- caret::train(
fml, data = train_clean, method = "rf",
trControl = ctrl,
preProcess = c("center","scale"),
tuneGrid = grid_rf,
ntree = 300,
importance = TRUE
)
# Gráfico estilo Sesión 04
print(ggplot(train.rf))
# 7) Evaluación en test
test_eval_mf <- model.frame(fml, data = test_df, na.action = na.pass)
ok_test <- stats::complete.cases(test_eval_mf)
test_clean <- test_df[ok_test, , drop = FALSE]
test_clean <- test_clean %>% dplyr::filter(!is.na(Precio_Unitario_Promedio))
pred.lm   <- predict(train.lm,   newdata = test_clean)
pred.mars <- predict(train.mars, newdata = test_clean)
pred.rf   <- predict(train.rf,   newdata = test_clean)
err.lm   <- test_clean$Precio_Unitario_Promedio - pred.lm
err.mars <- test_clean$Precio_Unitario_Promedio - pred.mars
err.rf   <- test_clean$Precio_Unitario_Promedio - pred.rf
rmse <- function(e) sqrt(mean(e^2, na.rm = TRUE))
mae  <- function(e) mean(abs(e), na.rm = TRUE)
mse  <- function(e) mean(e^2, na.rm = TRUE)
metrics <- data.frame(
Modelo = c("LM","MARS","RandomForest"),
RMSE   = c(rmse(err.lm), rmse(err.mars), rmse(err.rf)),
MAE    = c(mae (err.lm), mae (err.mars), mae (err.rf)),
MSE    = c(mse (err.lm), mse (err.mars), mse (err.rf))
)
print(metrics)
# 8) Boxplots de errores (como en el archivo del profe)
error.test <- data.frame(
lm   = err.lm,
mars = err.mars,
rf   = err.rf
)
par(mfrow = c(1,2))
boxplot(error.test); title(main="ML models", sub="Forecasting Errors")
boxplot(abs(error.test)); title(main="ML models", sub="Forecasting Absolute Errors")
par(mfrow = c(1,1))
# --- P3 con gráficos estilo Sesión 04 (base: precio_por_pais) ---
set.seed(5162)
# 0) Verificar columnas
req <- c("Ano","Mes","Pais","Sub_categoria","Precio_Unitario_Promedio")
stopifnot(all(req %in% names(precio_por_subcategoria)))
# 1) Dataset y factores
data_ag <- precio_por_subcategoria %>%
dplyr::select(all_of(req)) %>%
dplyr::mutate(
Pais          = as.factor(Pais),
Sub_categoria = as.factor(Sub_categoria),
Ano           = as.integer(Ano),
Mes           = as.integer(Mes)
) %>%
dplyr::filter(is.finite(Precio_Unitario_Promedio))
# (Opcional) colapsar subcategorías muy raras
min_count <- 5
tab_sc <- table(data_ag$Sub_categoria)
rare_sc <- names(tab_sc)[tab_sc < min_count]
if (length(rare_sc) > 0) {
data_ag$Sub_categoria <- forcats::fct_other(
data_ag$Sub_categoria,
keep = setdiff(levels(data_ag$Sub_categoria), rare_sc),
other_level = "Otros"
)
}
# 2) Split 80/20 estratificado por Sub_categoria
set.seed(5162)
idx <- caret::createDataPartition(data_ag$Sub_categoria, p = 0.8, list = FALSE)
train_df <- data_ag[idx, ]
test_df  <- data_ag[-idx, ]
# 3) Fórmula (solo variables de la tabla agregada)
fml <- Precio_Unitario_Promedio ~ Pais + Sub_categoria + Ano + Mes
# 4) Limpieza robusta
train_df <- train_df %>% dplyr::filter(!is.na(Precio_Unitario_Promedio))
mf_train <- model.frame(fml, data = train_df, na.action = na.pass)
stopifnot(nrow(mf_train) == nrow(train_df))
ok_train <- stats::complete.cases(mf_train)
train_clean <- train_df[ok_train, , drop = FALSE]
# 5) Control CV (10 folds)
ctrl <- caret::trainControl(method = "cv", number = 10)
# 6.1 LM (con resumen tipo modelsummary)
train.lm <- lm(fml, data = train_clean)
modelsummary(train.lm,
fmt = 3,
estimate = "{estimate}{stars}({std.error})",
statistic = NULL,
gof_map = c("nobs","adj.r.squared","rmse"))
# 6.2 MARS con gráfico de tuning (ggplot(train.mars))
set.seed(5162)
train.mars <- caret::train(
fml, data = train_clean, method = "earth",
trControl = ctrl,
preProcess = c("center","scale"),
tuneGrid = expand.grid(degree = c(1,2), nprune = 5:12)
)
# Gráfico estilo Sesión 04
print(ggplot(train.mars))
# 6.3 Random Forest con gráfico de tuning (ggplot(train.rf))
p <- length(all.vars(update(fml, . ~ . - Precio_Unitario_Promedio)))
mtry_heur <- max(1, floor(sqrt(p)))
grid_rf <- expand.grid(mtry = unique(pmax(1, c(mtry_heur-1, mtry_heur, mtry_heur+1))))
# --- 1. Preparación de datos (usando 'data_ag' como nombre principal) ---
set.seed(5162)
data_ag <- precio_por_subcategoria %>%
select(Ano, Mes, Pais, Sub_categoria, Precio_Unitario_Promedio) %>%
mutate(across(c(Pais, Sub_categoria), as.factor)) %>%
filter(is.finite(Precio_Unitario_Promedio))
# --- 2. División de datos ---
idx <- createDataPartition(data_ag$Sub_categoria, p = 0.8, list = FALSE)
train_df <- data_ag[idx, ]
test_df  <- data_ag[-idx, ]
fml <- Precio_Unitario_Promedio ~ . # Usar todas las demás variables como predictores
# --- 3. Entrenamiento de modelos ---
ctrl <- trainControl(method = "cv", number = 10, savePredictions = "final")
# Entrenamos los 3 modelos
modelo_lm   <- train(fml, data = train_df, method = "lm", trControl = ctrl)
modelo_mars <- train(fml, data = train_df, method = "earth", trControl = ctrl, tuneGrid = expand.grid(degree=1, nprune=5:12))
modelo_rf   <- train(fml, data = train_df, method = "rf", trControl = ctrl, tuneGrid = expand.grid(mtry = 2:4), ntree = 100)
# --- 4. Comparación de métricas de desempeño ---
model_list <- list(LM = modelo_lm, MARS = modelo_mars, RF = modelo_rf)
results <- resamples(model_list)
summary(results)
# --- 5. Predicción puntual y comparación con valor real ---
# a) Definimos el caso a predecir
new_caso <- data.frame(
Pais = factor("Chile", levels = levels(train_df$Pais)),
Sub_categoria = factor("Aceite", levels = levels(train_df$Sub_categoria)),
Ano  = 2022,
Mes  = 2
)
# b) Obtenemos las predicciones
predicciones <- sapply(model_list, function(modelo) predict(modelo, newdata = new_caso))
# c) Buscamos el valor real observado desde el dataframe principal 'data_ag'
obs <- data_ag %>%
dplyr::filter(Ano==2022, Mes==2, Pais=="Chile", Sub_categoria=="Aceite") %>%
dplyr::slice(1) %>%
dplyr::pull(Precio_Unitario_Promedio)
# d) Creamos la tabla final combinando predicciones y el valor observado
pred_puntual <- data.frame(
Modelo = names(predicciones),
Prediccion = predicciones,
Observado = obs
)
# e) Imprimimos el resultado final
print(pred_puntual)
# --- 1. Preparación de datos ---
set.seed(5162)
data_ag <- precio_por_subcategoria %>%
select(Ano, Mes, Pais, Sub_categoria, Precio_Unitario_Promedio) %>%
mutate(across(c(Pais, Sub_categoria), as.factor)) %>%
filter(is.finite(Precio_Unitario_Promedio))
# --- 2. División de datos ---
idx <- createDataPartition(data_ag$Sub_categoria, p = 0.8, list = FALSE)
train_df <- data_ag[idx, ]
test_df  <- data_ag[-idx, ]
fml <- Precio_Unitario_Promedio ~ .
# --- 3. Entrenamiento de modelos ---
ctrl <- trainControl(method = "cv", number = 10, savePredictions = "final")
modelo_lm   <- train(fml, data = train_df, method = "lm", trControl = ctrl)
modelo_mars <- train(fml, data = train_df, method = "earth", trControl = ctrl, tuneGrid = expand.grid(degree=1, nprune=5:12))
modelo_rf   <- train(fml, data = train_df, method = "rf", trControl = ctrl, tuneGrid = expand.grid(mtry = 2:4), ntree = 100)
# --- 4. Comparación de métricas de desempeño ---
model_list <- list(LM = modelo_lm, MARS = modelo_mars, RF = modelo_rf)
results <- resamples(model_list)
summary(results)
# --- 5. (NUEVO) Creación de Boxplots de Errores ---
# a) Realizamos las predicciones en el set de prueba
pred.lm   <- predict(modelo_lm,   newdata = test_df)
pred.mars <- predict(modelo_mars, newdata = test_df)
pred.rf   <- predict(modelo_rf,   newdata = test_df)
# b) Calculamos los errores de predicción (valor real - predicción)
error.df <- data.frame(
LM   = test_df$Precio_Unitario_Promedio - pred.lm,
MARS = test_df$Precio_Unitario_Promedio - pred.mars,
RF   = test_df$Precio_Unitario_Promedio - pred.rf
)
# c) Generamos los boxplots
# Primero, configuramos la ventana gráfica para mostrar dos gráficos juntos
par(mfrow = c(1, 2))
# Gráfico 1: Errores de predicción (para ver el sesgo)
boxplot(error.df, main = "Errores de Predicción")
# Gráfico 2: Errores absolutos (para ver la magnitud del error)
boxplot(abs(error.df), main = "Errores Absolutos de Predicción")
# Reseteamos la configuración de la ventana gráfica
par(mfrow = c(1, 1))
# --- 6. Predicción puntual y comparación con valor real ---
# (Esta parte del código sigue igual)
new_caso <- data.frame(
Pais = factor("Chile", levels = levels(train_df$Pais)),
Sub_categoria = factor("Aceite", levels = levels(train_df$Sub_categoria)),
Ano  = 2022,
Mes  = 2
)
predicciones <- sapply(model_list, function(modelo) predict(modelo, newdata = new_caso))
obs <- data_ag %>%
filter(Ano==2022, Mes==2, Pais=="Chile", Sub_categoria=="Aceite") %>%
slice(1) %>%
pull(Precio_Unitario_Promedio)
pred_puntual <- data.frame(
Modelo = names(predicciones),
Prediccion = predicciones,
Observado = obs
)
print(pred_puntual)
View(precio_por_subcategoria)
