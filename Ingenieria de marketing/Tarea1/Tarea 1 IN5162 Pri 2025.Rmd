---
title:  "Tarea 1 - IN5162, Semestre Primavera 2025"
author: Lamich, Muñoz, Venegas.
date:   "`r format(Sys.time(), '%d %B, %Y')`"

output:
  html_document:
    df_print: paged
    theme: simplex
    highlight: tango
    toc: no
encoding: UTF-8
---

<!-- 
Author  	  : Marcel Goic
Description	: Comparación de precios de Abarrotes
						- v.0.0 (14/Abr/2022). First Version
						- v.0.0 (14/Aug/2025). Add basket forecasting
Notes       : 
-->

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Preliminares

(0.0 puntos) Escriban acá todos los comandos que necesita ejecutar antes de abordar las preguntas de la tarea (carga de librerías, lectura de datos, limpieza de la data, transformación de variables y todo lo que necesite).

#### Preparación Tarea

```{r P0 Corremos libreria}
#Exploración de datos
library(readxl)
library(fixest)
library(ggplot2)
library(dplyr)
library(knitr)
library(glmnet)
library(kableExtra)
library(modelsummary)
library(caret)
library(earth)
library(randomForest)
library(tidyr)
```

```{r P0 Limpiamos objetos}

rm(list=ls())         # Limpia la lista de objetos 
graphics.off()        # Limpia la lista de gráficos
options(digits = 5)   # Número de dígitos a utilizar

```

```{r P0 Fijamos directorio}
setwd("/Users/leandrovenegas/Documents/GitHub/Uni/Ingenieria de marketing/Tarea1")  # fijando el directorio de trabajo
```

```{r P0 Leemos la base}
#Exploración de datos
# Leemos el archivo CSV.
datos_precios = read_excel("Canasta_de_productos.xlsx")

# Cargamos la base tipo de cambio.
Tipo_cambio <- read.csv("Tipo_cambio.csv")

# Cargamos la base de variables macros utilizadas.
macro <- read.csv("variables_macro.csv")



head(datos_precios)
head(Tipo_cambio)
head(macro)

```

Realizamos ajustes a la base de precios.

```{r P0 Transformamos la base}

# Renombramos la columna con _ para que sea intuitivo al momento de trabajar las bases.

datos_precios <- datos_precios %>% rename(Sub_categoria = `Sub-categoria`)

# Transformamos los años a numerico.
datos_precios$Ano <- as.numeric(datos_precios$Ano)

# Creamos una variable que se llame precio final, para explorar si existen cambios en cuanto a las ofertas que ofrecen las cadenas de supermercados.

datos_precios <- datos_precios %>%
  mutate(Precio_Final = ifelse(!is.na(Precio_Oferta) & Promocion == 1, Precio_Oferta, Precio_Normal))

#Y eliminamos precio oferta, ya que no lo necesitamos con la nueva variable
datos_precios <- datos_precios %>% select(-Precio_Oferta)

# Primero se definen los meses en orden
meses <- c("Enero", "Febrero", "Marzo", "Abril", "Mayo", "Junio",
           "Julio", "Agosto", "Septiembre", "Octubre", "Noviembre", "Diciembre")

# Luego se convierte la columna "Mes" en factor ordenado y después a número.
datos_precios$Mes <- match(datos_precios$Mes, meses)
datos_precios$Mes <- as.numeric(datos_precios$Mes)

#print(datos_precios$Mes) Corroboramos.
````


Ajustamos las base tipo de cambio para unirla con la de precios.

```{r Uniendo base precios con tipo de cambio}
#Pasar a formato largo (de columnas de países a columna Pais + TipoCambio)
Tipo_Cambio <- Tipo_cambio %>%
  pivot_longer(
    cols = c(Argentina, Chile, Colombia, España, Perú, Portugal, UK),
    names_to = "Pais",
    values_to = "TipoCambio"
  )

#View(Tipo_Cambio) #Vemos como ordenamos los datos.

#Unir con la base de precios (df_precios)
datos_precios_tc <- datos_precios %>%
  left_join(Tipo_Cambio, by = c("Pais", "Ano", "Mes")) %>%
  mutate(
    Precio_Normal_usd = Precio_Normal * TipoCambio,
    Precio_Final_usd  = Precio_Final  * TipoCambio
  )

#ademas agregamos precio unitario, para considerar el precio por volumen.
datos_precios_tc <- datos_precios_tc %>%
  mutate(PrecioU_oferta_usd = Precio_Final_usd/Peso_Volumen, PrecioU_Normal_usd = Precio_Normal_usd/Peso_Volumen)

#View(datos_precios_tc) #Veamos como quedaron los datos.

#Limpiamos las columnas que no utilizaremos

datos_precios_tc <- datos_precios_tc %>%
  select(-Date,-Precio_Final,-Precio_Normal,-TipoCambio,-Precio_Final_usd,-Precio_Normal_usd,-Peso_Volumen)

#View(datos_precios_tc) # Resultado final

```



## Posiblemente eliminemos esta celda
```{r}
# --- Filtrado y conteo de Peso_Volumen ---
# Contar productos menores a 0.1 y mayores/iguales
#conteo_menores <- datos_precios_tc %>% filter(Peso_Volumen < 0.1) %>% nrow()
#conteo_mayores <- datos_precios_tc %>% filter(Peso_Volumen >= 0.1) %>% nrow()

#cat("Productos con Peso_Volumen < 0.1:", conteo_menores, "\n")
#cat("Productos con Peso_Volumen >= 0.1:", conteo_mayores, "\n")

# Eliminar los que son menores a 0.1, porque son solo el 8% de los datos 
#datos_precios_tc <- datos_precios_tc %>% filter(Peso_Volumen >= 0.1)

# Revisar estructura final
#summary(datos_precios_tc$Peso_Volumen)
#View(datos_precios_tc)
```


Ademas no todas las columnas son importantes, no podemos comparar el precio de la sal, azucar y endulzante por ejemplo. Para esto debemos agrupar los productos por el tipo de producto, es decir todas las azucar que se venden en chile se deben agrupar en alguna unica.

Por lo que, hacemos un group by para subcategoria y categoria, calculamos el promedio y exploramos la base para la pregunta 1:

```{r agrupamos por sub_categoria Y Pais}
precio_por_subcategoria <- datos_precios_tc %>%
  group_by(Ano, Mes, Pais, Sub_categoria) %>%
  summarise(Precio_Unitario_Promedio = mean(PrecioU_oferta_usd, na.rm = TRUE))# %>%

#Subimos el nivel de agregación, para usar solo categoria.
precio_por_categoria <- datos_precios_tc %>%
  group_by(Pais, Categoria) %>%
  summarise(Precio_Unitario_Promedio = mean(PrecioU_oferta_usd, na.rm = TRUE))# %>%

#Subimos el nivel de agregación, para usar solo 1 conjunto de productos y obtenemos promedio.
precio_por_pais <- datos_precios_tc %>%
  group_by(Pais) %>%
  summarise(Precio_Unitario_Promedio = mean(PrecioU_oferta_usd, na.rm = TRUE))# %>%

```

Existen subcategorias, que en verdad no nos importan tanto, y nos mueven algunos precios en exceso debido a su peso minimo.

```{r eliminamos subcategorías o categorias que están mal}
# Eliminar subcategorías específicas
precio_por_subcategoria <- precio_por_subcategoria %>%
  filter(!Sub_categoria %in% c("Ajo", "Albahaca", "Oregano", 
                               "Endulzante", "Canela", 
                               "Laurel", "Chocolate", "Té","Te","Café","Dulces","Aceto"))


# Eliminar categorías específicas
precio_por_categoria <- precio_por_categoria %>%
  filter(!Categoria %in% c("Especias, condimentos y caldos",
                           "Azúcar, sal y sucedáneos",
                           "Cafe y te",
                           "Café y té",
                           "Dulces y postres no congelados sin cereales",
                           "Sopas"))

```

Ademas debemos asegurarnos que las mismas categorias y subcategorias tienen que estar para todos los paises.

```{r}

# Filtramos directamente, manteniendo solo las categorías y subcategorias que aparecen en todos los paises.

precio_por_subcategoria <- precio_por_subcategoria %>%
  group_by(Sub_categoria) %>%
  filter(n_distinct(Pais) == 7) %>%
  ungroup()

precio_por_categoria <- precio_por_categoria %>%
  group_by(Categoria) %>%
  filter(n_distinct(Pais) == 7) %>%
  ungroup()

```

Luego de estudiar la base, agregamos variables que podrian explicar el modelo. Y la unimos a nuestra anterior base.

```{r Unimos la base de subcategoria con los datos macroeconomicos}

# Unir bases por País y Año, con variables macro Y micro para pregunta 2.
precio_por_subcategoria1 <- datos_precios_tc %>%
  group_by(Ano, Sub_categoria, Pais) %>%
  summarise(Precio_Unitario_Promedio = mean(PrecioU_oferta_usd, na.rm = TRUE)) %>%
  ungroup()

# Unimos con macro
data_macro <- precio_por_subcategoria1 %>%
  inner_join(macro, by = c("Pais", "Ano")) %>%
  mutate(GDPpc_miles = GDPpc / 1000)


data_micro <- datos_precios_tc %>%
  mutate(
    MarcaPropia = as.factor(Marca_propia),
    Promocion = as.factor(Promocion)
  )

```

## Desarrollo

Documenten acá el desarrollo de su tarea por pregunta.

#### Pregunta 1

(1.0 puntos) Exploren los datos para entender la distribución del precio de los abarrotes y ver qué variables podrían ayudar a explicar posibles diferencias en el nivel de precios entre países.




```{r P1}
#Exploración de datos

# Generamos el gráfico de dispersión
ggplot(precio_por_subcategoria, aes(x = Sub_categoria, y = Precio_Unitario_Promedio, color = Pais)) +
  geom_jitter(width = 0.25, alpha = 0.7, size = 2.5) + # Jitter para evitar solapamiento
  labs(
    title = "Dispersión de Precios Promedio por Subcategoría y País",
    subtitle = "Cada punto es el precio promedio de una categoría en un país",
    x = "Subcategoría de Producto",
    y = "Precio Unitario Promedio (USD)",
    color = "País"
  ) +
  theme_minimal() +
  theme(
    axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1) # Rotar etiquetas del eje X
  )
```







Exploramos solo por un conjunto de productos.

```{r}

#Mini filtro por algunos paises.
precio_categorias_comunes <- precio_por_categoria %>%
  filter(Pais %in% c("Perú", "Colombia", "UK"))

#Graficamos.
ggplot(precio_categorias_comunes, aes(x = Categoria, y = Precio_Unitario_Promedio, color = Pais)) +
  geom_jitter(width = 0.25, alpha = 0.7, size = 2.5) + # Jitter para evitar solapamiento
  labs(
    title = "Dispersión de Precios Promedio por Subcategoría y País",
    subtitle = "Cada punto es el precio promedio de una categoría en un país",
    x = "Categoría de Producto",
    y = "Precio Unitario Promedio (USD)",
    color = "País"
  ) +
  theme_minimal() +
  theme(
    axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1) # Rotar etiquetas del eje X
  )

```

Esto se hizo para entender una muestra, por ejemplo se ve que UK parece ser el más caro de los 3 y Colombia el más barato.

```{r}

#Graficamos promediando todos los productos de un pais.
ggplot(precio_por_pais, aes(x = Pais, y = Precio_Unitario_Promedio)) +
  geom_jitter(width = 0.25, alpha = 0.7, size = 2.5) + # Jitter para evitar solapamiento
  labs(
    title = "Dispersión de Precios Promedio por Subcategoría y País",
    subtitle = "Cada punto es el precio promedio de una categoría en un país",
    x = "Categoría de Producto",
    y = "Precio Unitario Promedio (USD)",
    color = "País"
  ) +
  theme_minimal() +
  theme(
    axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1) # Rotar etiquetas del eje X
  )
```

Luego de ver visualmente la distribución de variables, podriamos estudiar el ranking de paises baratos/caros, usando un ranking.Esto porque al promediar, se está sobreponderando a los productos más caros. Luego el ranking asigna un número del 1 al 7, donde 7 corresponde al país más caro.

### Hacemos un ranking a nivel promedio completo de productos.


```{r}

# Ranking por producto y año
ranking_productos <- precio_por_subcategoria %>%
  group_by(Ano, Sub_categoria) %>%
  mutate(Rank_del_Pais = rank(Precio_Unitario_Promedio, ties.method = "first")) %>%
  ungroup()

# Ranking agregado por país
ranking_final <- ranking_productos %>%
  group_by(Pais) %>%
  summarise(RankTotal = sum(Rank_del_Pais, na.rm = TRUE)) %>%
  arrange(RankTotal)

# 4. Resultado
print(ranking_final)
```
Este ranking se corresponde con la intuición y experiencia donde de forma absoluta, es más caro UK y más barato Colombia.


Luego de estudiar la base, agregamos variables que podrian explicar el modelo. Y la unimos a nuestra anterior base.


#### Pregunta 2

Usando los aprendizajes derivados de la exploración de datos, utilicen un enfoque de regresión lineal para examinar cuantitativamente qué factores determinan los distintos niveles de precios que pueden haber. En particular, consideren que nos interesa comparar niveles de precios entre países. 
     
a. (1.0 puntos) Propongan al menos dos especificaciones alternativas para el objetivo propuesto. Justifiquen muy brevemente por qué las variables explicativas que está incluyendo en el modelo tienen sentido desde el punto de vista del problema. Justifiquen además el nivel de agregación escogido y los índices considerados en el modelo.

Primero proponemos una especificación solo con variables macro externas y haremos otra con variables de la base, como categoría por ejemplo. Esto dado que como son solo 7 países, se tiene muy poca varianza solo con las variables macro por país y para 2 años.

El nivel de agregación escogido es el precio por subcategoría dado que por ejemplo leche de chocolate o normal es indiferente y como se vio antes tienen precios similares, en un país determinado y en un tiempo determinado. Por esta razón se agregan efectos fijos por estas 3 variables.

```{r}
# ============================
# Modelo Macro con efectos fijos
# ============================

#Ya tenemos cargada la base de macros, y transformada en P0.
# Estimamos con efectos fijos
modelo_macro_fe <- feols(
  Precio_Unitario_Promedio ~ GDPpc_miles + Arancel + UrbGrow +
    LPI + Inflacion + Import_PIB + FoodImp | Sub_categoria + Ano,
  data = data_macro
)

summary(modelo_macro_fe)

  


```

```{r}
# ============================
# Modelo Micro con efectos fijos
# ============================

#Datos cargados micro en P0.

modelo_micro_fe <- feols(
  PrecioU_oferta_usd ~ MarcaPropia + Promocion + Cadena |
    Categoria + Pais + Ano,
  data = data_micro
)

summary(modelo_micro_fe)


```


Como comentario, se filtra para que no aparezcan categoría, país, año porque son efectos fijos, no regresores. Por tanto, cuando Lasso muestra los regresores que seleccionó, no debe incluirlos.




  





b. (1.0 puntos) Sobre los dos modelos planteados en la parte anterior, apliquen algún método de selección automática de variables aprendido en clases y compare con respecto a los resultados anteriores. Deben indicar cuáles variables descartan.

```{r P2_b}
#automatic variable selection

#1. Construcción de la base filtrando NA
data_macro_lasso <- data_macro %>%
dplyr::select(Precio_Unitario_Promedio, GDPpc_miles, Arancel, UrbGrow, LPI, Inflacion, Import_PIB, FoodImp) %>%
na.omit()
# 2. Variable dependiente
y_macro <- as.matrix(data_macro_lasso$Precio_Unitario_Promedio) 
# 3. Matriz de regresores (incluye efectos fijos como dummies)
X_macro <- model.matrix( Precio_Unitario_Promedio ~ GDPpc_miles + Arancel + UrbGrow + LPI + Inflacion + Import_PIB + FoodImp , data = data_macro_lasso )[, -1] # quitamos el intercepto 
# 4. Estimación con LASSO y validación cruzada
set.seed(123) # para replicabilidad 
cv_macro_lasso <- cv.glmnet(X_macro, y_macro, alpha = 1, standardize = TRUE)
# 5. Lambda óptimo elegido por CV 
cat("Lambda óptimo:", cv_macro_lasso$lambda.min, "\n")
# 6. Coeficientes del modelo
coef_macro <- coef(cv_macro_lasso, s = "lambda.min")
# 7. Variables seleccionadas(coef distinto de 0) 
selected_vars <- rownames(coef_macro)[which(coef_macro != 0)] 
cat("Variables seleccionadas por LASSO:\n")
print(selected_vars)

 # 1. Construcción de la base filtrando NA
  data_micro_lasso <- data_micro %>%
    dplyr::select(PrecioU_oferta_usd, MarcaPropia, Promocion, Cadena, Categoria, Pais, Ano) %>%
    na.omit()

  # 2. Variable dependiente
  y_micro <- as.matrix(data_micro_lasso$PrecioU_oferta_usd)

  # 3. Matriz de regresores (incluye efectos fijos como dummies)
  X_micro <- model.matrix(
    PrecioU_oferta_usd ~ MarcaPropia + Promocion + Cadena +
      factor(Categoria) + factor(Pais) + factor(Ano),
    data = data_micro_lasso
  )[, -1]   # quitamos el intercepto

  # 4. Estimación con LASSO y validación cruzada
  set.seed(123)  # para replicabilidad
  cv_micro_lasso <- cv.glmnet(X_micro, y_micro, alpha = 1, standardize = TRUE)

  # 5. Lambda óptimo elegido por CV
  cat("Lambda óptimo:", cv_micro_lasso$lambda.min, "\n")

  # 6. Coeficientes del modelo
  coef_micro <- coef(cv_micro_lasso, s = "lambda.min")
  
# 7. Variables seleccionadas (coef distinto de 0)
selected_vars_micro <- rownames(coef_micro)[which(coef_micro != 0)]
 # Filtrar: eliminar intercepto, dummies de Categoria, Pais y Ano
selected_vars_micro_clean <- selected_vars_micro[!grepl("Intercept|Categoria|Pais|Ano", selected_vars_micro)]

cat("Variables seleccionadas por LASSO (solo micro, sin FE):\n")
print(selected_vars_micro_clean)

```

#### Pregunta 3

(1.0 puntos) Usen al menos dos de los modelos de aprendizaje de máquinas que vimos en clases (MARS, kNN, regression tree o random forest) para generar un pronóstico de precios para un país, año, mes y produto dado. Comparen la capacidad de estos modelos con respecto a los de regresión lineal utilizando métricas de desempeño (MSE, RMSE o MAE). Discutan brevemente sus resultados y el modelo que recomendaría usar.

```{r P3}
#Machine learning models

set.seed(851)

# 0) Verificación
req_cols <- c("Pais","Ano","Mes","Sub_categoria","Precio_Unitario_Promedio",
              "GDPpc","Arancel","UrbGrow","LPI","Inflacion","Import_PIB","FoodImp")
faltan <- setdiff(req_cols, names(data_completa))
if (length(faltan) > 0) stop(paste("Faltan columnas en data_completa:", paste(faltan, collapse=", ")))
````


```{r}

# 1) Split temporal: entrenamiento 2021, test 2022
train_df <- subset(data_completa, Ano == 2021)
test_df  <- subset(data_completa, Ano == 2022)

# 2) Fórmulas
fml_lin <- Precio_Unitario_Promedio ~ GDPpc + Arancel + UrbGrow + LPI + Inflacion + Import_PIB + FoodImp
fml_int <- as.formula("Precio_Unitario_Promedio ~ (GDPpc + Arancel + UrbGrow + LPI + Inflacion + Import_PIB + FoodImp)^2")

# 3) Control CV
ctrl <- trainControl(method = "cv", number = 10)

```


```{r}

# 4) Modelos
# 4.1 LM baseline y stepwise
lm_lin  <- lm(fml_lin, data = train_df)
lm_step <- step(lm(fml_int, data = train_df), direction = "backward", trace = 0)

# 4.2 MARS
mars_fit <- train(
  fml_int,
  data = train_df,
  method = "earth",
  trControl = ctrl,
  preProcess = c("center","scale"),
  tuneGrid = expand.grid(degree = c(1,2), nprune = 5:9)
)

# 4.3 Random Forest
rf_fit <- train(
  fml_int,
  data = train_df,
  method = "rf",
  trControl = ctrl,
  preProcess = c("center","scale"),
  tuneGrid = expand.grid(mtry = 2:6),
  importance = TRUE
)

# 5) Predicciones sobre 2022
pred_lm_lin  <- predict(lm_lin,  newdata = test_df)
pred_lm_step <- predict(lm_step, newdata = test_df)
pred_mars    <- predict(mars_fit, newdata = test_df)
pred_rf      <- predict(rf_fit,   newdata = test_df)

# 6) Métricas de desempeño (comparar qué modelo predice mejor 2022)
rmse <- function(y, yhat) sqrt(mean((y - yhat)^2, na.rm = TRUE))
mae  <- function(y, yhat) mean(abs(y - yhat), na.rm = TRUE)
mse  <- function(y, yhat) mean((y - yhat)^2, na.rm = TRUE)

y_test <- test_df$Precio_Unitario_Promedio

metrics <- data.frame(
  Modelo = c("LM (lineal)", "LM (stepwise)", "MARS", "RandomForest"),
  RMSE   = c(rmse(y_test, pred_lm_lin),
             rmse(y_test, pred_lm_step),
             rmse(y_test, pred_mars),
             rmse(y_test, pred_rf)),
  MAE    = c(mae (y_test, pred_lm_lin),
             mae (y_test, pred_lm_step),
             mae (y_test, pred_mars),
             mae (y_test, pred_rf)),
  MSE    = c(mse (y_test, pred_lm_lin),
             mse (y_test, pred_lm_step),
             mse (y_test, pred_mars),
             mse (y_test, pred_rf))
)
print(metrics)

# 7) Ejemplo de predicción puntual (Chile, feb 2022, Cebolla)
caso <- subset(test_df, Pais=="Chile" & Ano==2022 & Mes==2 & Sub_categoria=="Cebolla")
if (nrow(caso) == 0) {
  warning("No hay registros para (Chile, 2022-02, Cebolla) en test_df.")
} else {
  needed <- c("GDPpc","Arancel","UrbGrow","LPI","Inflacion","Import_PIB","FoodImp")
  if (!all(complete.cases(caso[, needed]))) {
    warning("El caso específico tiene NAs en predictoras; considera imputar valores.")
  }
  pred_caso <- data.frame(
    Modelo = c("LM (lineal)","LM (stepwise)","MARS","RandomForest"),
    Prediccion = c(
      predict(lm_lin,   newdata = caso),
      predict(lm_step,  newdata = caso),
      predict(mars_fit, newdata = caso),
      predict(rf_fit,   newdata = caso)
    )
  )
  print(pred_caso)
}

```

#### Pregunta 4
En vez de pedir que generen una canasta para cada mes año y pais, sugeriría que eligan 3 canasta con al menos 5 productos de su elección y pronostiquen el precio para todos los paises en una fecha en particular. Asi tenemos más variación en las respuestas y dificultamos la copia.

a. (1.0 puntos) Elaboren tres canastas de abarrotes con al menos cinco productos de sus preferencias para todos los países en alguna fecha cualquiera. Pronostiquen su precio corregido por moneda (USD) incluyendo variables explicativas relevantes. Comparen el precio de Chile con respecto al resto de países. 

```{r P4a}

# Asumimos que tu dataframe original se llama 'data_micro'

# --- PASO CLAVE: LIMPIEZA DE DATOS ---
# Eliminamos las filas donde el precio sea NA antes de hacer cualquier otra cosa
data_limpia <- data_micro %>%
  filter(!is.na(PrecioU_oferta_usd))

# --- Ahora sí, dividimos el dataframe LIMPIO ---
set.seed(123) # Para que la división de datos sea reproducible

# Dividir los datos en entrenamiento (80%) y prueba (20%)
indices_entrenamiento <- createDataPartition(data_limpia$PrecioU_oferta_usd, p = 0.8, list = FALSE)
datos_entrenamiento <- data_limpia[indices_entrenamiento, ]
datos_prueba <- data_limpia[-indices_entrenamiento, ]


# --- ENTRENAMIENTO DE MODELOS ---

# 1. Modelo de Regresión Lineal (como base de comparación)
modelo_lm <- lm(PrecioU_oferta_usd ~ Promocion + Marca_propia + Cadena, data = datos_entrenamiento)

# 2. Modelo k-Nearest Neighbors (kNN)
control_entrenamiento <- trainControl(method = "cv", number = 10)
modelo_knn <- train(PrecioU_oferta_usd ~ Promocion + Marca_propia + Cadena, 
                    data = datos_entrenamiento, 
                    method = "knn",
                    trControl = control_entrenamiento,
                    preProcess = c("center", "scale"),
                    tuneGrid = expand.grid(k = c(3, 5, 7, 9)))

# 3. Modelo Random Forest
#modelo_rf <- train(PrecioU_oferta_usd ~ Promocion + Marca_propia + Cadena, 
#                   data = datos_entrenamiento, 
#                   method = "rf",
#                   trControl = control_entrenamiento,
#                   preProcess = c("center", "scale"),
#                   tuneGrid = expand.grid(.mtry = c(2, 3)), # Ajustado a 3 predictores
#                   ntree = 100)

# --- EVALUACIÓN DE MODELOS ---

# Realizar predicciones en el set de prueba
predicciones_lm <- predict(modelo_lm, newdata = datos_prueba)
predicciones_knn <- predict(modelo_knn, newdata = datos_prueba)
#predicciones_rf <- predict(modelo_rf, newdata = datos_prueba)


```

b. (0.5 puntos) Utilicen las mismas canastas de abarrotes y pronostiquen su precio corregido por moneda (USD) y por paridad de poder adquisitivo (ppa) incluyendo variables explicativas relevantes. Comparen el precio de Chile con respecto al resto de países. Expliquen brevemente en qué se diferencia esta métrica en comparación a solo corregir por moneda.

```{r P4b}
# pronóstico de canasta de abarrotes corregido por moneda y por ppa

```

## Resumen

(0.5 puntos) Resuman ejecutivamente sus resultados y provean un resumen conciso de los aprendizajes y sugerencias relevantes.

```{r Resumen}
#Summary
```

## Anexos

Documenta acá cualquier otro adicional que consideres útil tener de referencia. 


## Roles

Todos los participantes del grupo de trabajo declaran que su participación queda bien reflejada en la siguiente tabla.  

```{r, message=FALSE, echo=FALSE, warning=FALSE}
library(dplyr)
library(kableExtra)

roles <- data.frame(
  integrantes = c("Integrante 1", "Integrante 2", "Integrante 3"),
  P1 = c("código", "interpretación", "código e interpretación"),
  P2 = c("interpretación", "-", "código e interpretación"),
  P3 = c("-", "-", "código e interpretación"),
  P4 = c("interpretación", "interpretación", "código"),
  Resumen = c("interpretación", "código", "-")
)

roles %>%
  kbl(caption = "**Tabla N+1:** Roles de los Participantes en el trabajo") %>%
  kable_classic(full_width = FALSE, html_font = "Cambria")
```


Asimismo, los participantes del grupo de trabajo declaran que el uso de herramientas de inteligencia artificial (IA) queda bien reflejada en la siguiente tabla.
```{r, echo=FALSE}
iarole <- data.frame(
  preguntas = c("P1", "P2", "P3", "P4", "Resumen"), 
  uso = c("escribir códigos para formatear los datos", 
          "interpretar los resultados", 
          "-", 
          "-", 
          "Encontrar errores en el código"), 
  herramienta = c("Chat GPT-5", 
                  "Ninguna", 
                  "Chat GPT-5", 
                  "Chat GPT-5", 
                  "Chat GPT-5, DeepSeek")
)

iarole %>%
  kbl(caption = "**Tabla N+2:** Rol de la IA en el trabajo") %>%
  kable_classic(full_width = F, html_font = "Cambria")

```
